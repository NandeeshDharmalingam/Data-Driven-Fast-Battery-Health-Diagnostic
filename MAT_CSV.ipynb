{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THIS IS TO EXTRACT THE DATA FROM .mat File  ->  .csv file  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THIS FUNCTION EXTRACTS THE FILES AND CONVERST THEM FROM \"SPECIFIED FOLDER\" : SPECIFIYING THE FOLDERS IS DONE MANUAALLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_save_mat_files(folder_path, columns_to_extract):\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith('.mat'):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            mat_data = scipy.io.loadmat(file_path, squeeze_me=True, struct_as_record=False)\n",
    "            dataset = mat_data.get('Dataset')\n",
    "\n",
    "            if not dataset:\n",
    "                print(f\"No 'Dataset' found in {file}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            data = {}\n",
    "            array_lengths = {}\n",
    "\n",
    "            for field in columns_to_extract:\n",
    "                # Navigate through potentially nested structures safely\n",
    "                field_value = getattr(dataset, field, None)\n",
    "                if field_value is not None:\n",
    "                    if isinstance(field_value, np.ndarray):\n",
    "                        data[field] = field_value.squeeze()\n",
    "                        array_lengths[field] = len(data[field])\n",
    "                    else:\n",
    "                        data[field] = field_value\n",
    "                        array_lengths[field] = 1\n",
    "\n",
    "            if len(set(array_lengths.values())) == 1:\n",
    "                df = pd.DataFrame(data)\n",
    "                csv_file_name = 'extracted_' + os.path.splitext(file)[0] + '.csv'\n",
    "                csv_file_path = os.path.join(folder_path, csv_file_name)\n",
    "                df.to_csv(csv_file_path, index=False)\n",
    "                print(f\"Processed and saved: {csv_file_name}\")\n",
    "            else:\n",
    "                print(f\"Skipping file '{file}' due to columns having different lengths.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPECIFY THE FOLDER TO BE EXTRACTED ALSO CHANGE THE LIST TO EXTRAXT THE SPECIFIC COLOUMNS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():             \n",
    "    '''# Define the columns you want to extract from cyclic ageging  \n",
    "    columns_to_extract = [\n",
    "        'Time', 'DataSet', 'tStep', 'Line', 'Command', 'U', 'I', 'Ah', 'AhStep', 'AhSet',\n",
    "        'AhChSet', 'AhDisSet', 'Wh', 'WhStep', 'T1', 'RAC', 'RDC', 'CycCount', 'Count',\n",
    "        'State', 'i_cut_hi', 'i_cut_lo', 'i_cut_low', 'i_cut_high'\n",
    "    ]'''\n",
    "\n",
    "    # Define the columns you want to extract from checkup cyclic aging\n",
    "    columns_to_extract = [\n",
    "        'Time', 'DataSet', 'tStep', 'Line', 'Command', 'U', 'I', 'Ah', 'AhStep', 'AhSet',\n",
    "         'Wh',  'T1', 'RAC', 'RDC', 'CycCount', \n",
    "        'State']\n",
    "    folder_path = 'E:\\Thesis CEVT\\Dataset\\TUM\\CU_CYC'\n",
    "    extract_and_save_mat_files(folder_path, columns_to_extract)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: extracted_BW-VTC-210_2228_CU_cyc_000_BW-VTC-CYC.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
